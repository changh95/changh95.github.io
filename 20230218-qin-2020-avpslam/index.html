<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.2">

<link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin>
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.1/css/all.min.css">

<script class="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"changh95.github.io","root":"/","images":"/images","scheme":"Pisces","version":"8.0.2","exturl":true,"sidebar":{"position":"right","display":"post","padding":18,"offset":12},"copycode":true,"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":true,"lazyload":false,"pangu":false,"comments":{"style":"disqus","active":false,"storage":false,"lazyload":false,"nav":null},"motion":{"enable":false,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":"auto","trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}};
  </script>
<meta name="description" content="VINS-Mono와 RoadMap의 저자인 Qin의 semantic slam 논문을 리뷰합니다.">
<meta property="og:type" content="article">
<meta property="og:title" content="Qin 2020 - AVP-SLAM - Semantic Visual Mapping and Localization for Autonomous Vehicles in the Parking Lot">
<meta property="og:url" content="https://changh95.github.io/20230218-qin-2020-avpslam/index.html">
<meta property="og:site_name" content="cv-learn">
<meta property="og:description" content="VINS-Mono와 RoadMap의 저자인 Qin의 semantic slam 논문을 리뷰합니다.">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://changh95.github.io/20230218-qin-2020-avpslam/Screenshot%202023-02-28%20at%202.34.23%20PM.png">
<meta property="og:image" content="https://changh95.github.io/20230218-qin-2020-avpslam/Screenshot%202023-02-28%20at%202.34.40%20PM.png">
<meta property="og:image" content="https://changh95.github.io/20230218-qin-2020-avpslam/Screenshot%202023-02-28%20at%202.36.52%20PM.png">
<meta property="og:image" content="https://changh95.github.io/20230218-qin-2020-avpslam/Screenshot%202023-02-28%20at%203.05.05%20PM.png">
<meta property="og:image" content="https://changh95.github.io/20230218-qin-2020-avpslam/Screenshot%202023-02-28%20at%203.18.49%20PM.png">
<meta property="og:image" content="https://changh95.github.io/20230218-qin-2020-avpslam/Screenshot%202023-02-28%20at%203.18.53%20PM.png">
<meta property="og:image" content="https://changh95.github.io/20230218-qin-2020-avpslam/Screenshot%202023-02-28%20at%203.46.55%20PM.png">
<meta property="og:image" content="https://changh95.github.io/20230218-qin-2020-avpslam/Screenshot%202023-02-28%20at%203.18.11%20PM.png">
<meta property="og:image" content="https://changh95.github.io/20230218-qin-2020-avpslam/Screenshot%202023-02-28%20at%204.05.37%20PM.png">
<meta property="og:image" content="https://changh95.github.io/20230218-qin-2020-avpslam/Screenshot%202023-02-28%20at%203.55.05%20PM.png">
<meta property="og:image" content="https://changh95.github.io/20230218-qin-2020-avpslam/Screenshot%202023-02-28%20at%204.01.14%20PM.png">
<meta property="og:image" content="https://changh95.github.io/20230218-qin-2020-avpslam/Screenshot%202023-02-28%20at%204.03.39%20PM.png">
<meta property="og:image" content="https://changh95.github.io/20230218-qin-2020-avpslam/Screenshot%202023-02-28%20at%204.04.46%20PM.png">
<meta property="article:published_time" content="2023-02-18T03:50:21.000Z">
<meta property="article:modified_time" content="2023-06-09T06:12:02.735Z">
<meta property="article:author" content="cv-learn">
<meta property="article:tag" content="SLAM">
<meta property="article:tag" content="Visual-SLAM">
<meta property="article:tag" content="Semantic SLAM">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://changh95.github.io/20230218-qin-2020-avpslam/Screenshot%202023-02-28%20at%202.34.23%20PM.png">


<link rel="canonical" href="https://changh95.github.io/20230218-qin-2020-avpslam/">


<script class="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>
<title>Qin 2020 - AVP-SLAM - Semantic Visual Mapping and Localization for Autonomous Vehicles in the Parking Lot | cv-learn</title>
  



  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .menu-item,
  .use-motion .sidebar,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header {
    visibility: visible;
  }

  .use-motion .header,
  .use-motion .site-brand-container .toggle,
  .use-motion .footer { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle,
  .use-motion .custom-logo-image {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
</noscript>

<style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"] > svg a {
  fill: blue;
  stroke: blue;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">cv-learn</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">Vision, SLAM, Spatial AI</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <section class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%EB%85%BC%EB%AC%B8-%EC%9A%94%EC%95%BD"><span class="nav-number">1.</span> <span class="nav-text">논문 요약</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%EC%8B%9C%EC%8A%A4%ED%85%9C-%EC%98%A4%EB%B2%84%EB%B7%B0"><span class="nav-number">2.</span> <span class="nav-text">시스템 오버뷰</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#IPM-%EC%9D%B4%EB%AF%B8%EC%A7%80-%EC%83%9D%EC%84%B1"><span class="nav-number">3.</span> <span class="nav-text">IPM 이미지 생성</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Semantic-feature-detection"><span class="nav-number">4.</span> <span class="nav-text">Semantic feature detection</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Local-mapping"><span class="nav-number">5.</span> <span class="nav-text">Local mapping</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Loop-detection"><span class="nav-number">6.</span> <span class="nav-text">Loop detection</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Global-optimization"><span class="nav-number">7.</span> <span class="nav-text">Global optimization</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Localization"><span class="nav-number">8.</span> <span class="nav-text">Localization</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%EC%8B%A4%ED%97%98-%EA%B2%B0%EA%B3%BC"><span class="nav-number">9.</span> <span class="nav-text">실험 결과</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Related-works"><span class="nav-number">10.</span> <span class="nav-text">Related works</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%EA%B4%80%EB%A0%A8-%EC%9C%A0%ED%88%AC%EB%B8%8C-%EC%98%81%EC%83%81"><span class="nav-number">11.</span> <span class="nav-text">관련 유투브 영상</span></a></li></ol></div>
        </section>
        <!--/noindex-->

        <section class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">cv-learn</p>
  <div class="site-description" itemprop="description">Vision, SLAM, Spatial AI</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">253</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">43</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
        <span class="site-state-item-count">351</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2NoYW5naDk1" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;changh95"><i class="fab fa-github fa-fw"></i></span>
      </span>
  </div>



        </section>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://changh95.github.io/20230218-qin-2020-avpslam/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="cv-learn">
      <meta itemprop="description" content="Vision, SLAM, Spatial AI">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="cv-learn">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Qin 2020 - AVP-SLAM - Semantic Visual Mapping and Localization for Autonomous Vehicles in the Parking Lot
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-02-18 12:50:21" itemprop="dateCreated datePublished" datetime="2023-02-18T12:50:21+09:00">2023-02-18</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2023-06-09 15:12:02" itemprop="dateModified" datetime="2023-06-09T15:12:02+09:00">2023-06-09</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/1-Spatial-AI/" itemprop="url" rel="index"><span itemprop="name">1. Spatial AI</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/1-Spatial-AI/1-1-SLAM/" itemprop="url" rel="index"><span itemprop="name">1.1 SLAM</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/1-Spatial-AI/1-1-SLAM/%EB%85%BC%EB%AC%B8-%EB%A6%AC%EB%B7%B0/" itemprop="url" rel="index"><span itemprop="name">논문 리뷰</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">Views: </span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h1 id="논문-요약"><a href="#논문-요약" class="headerlink" title="논문 요약"></a>논문 요약</h1><p>이 논문에서는 지하 주차장에서 Semantic 정보로 이뤄져있는 지도를 만들고, 관리하고, visual localization 및 planning 목적으로 사용하는 프레임워크를 제안한다. </p>
<p>지도는 주차장 노면에서 검출 가능한 road marker 및 주변 환경에서 검출 가능한 물체들로 이뤄져있고, semantic 정보만을 포함하기에 굉장히 적은 용량을 요구한다.</p>
<img src="/20230218-qin-2020-avpslam/Screenshot%202023-02-28%20at%202.34.23%20PM.png" class="" title="Semantic map of underground parking lot">
<img src="/20230218-qin-2020-avpslam/Screenshot%202023-02-28%20at%202.34.40%20PM.png" class="" title="Planning and control">
<p> </p>
<hr>
<h1 id="시스템-오버뷰"><a href="#시스템-오버뷰" class="headerlink" title="시스템 오버뷰"></a>시스템 오버뷰</h1><img src="/20230218-qin-2020-avpslam/Screenshot%202023-02-28%20at%202.36.52%20PM.png" class="" title="system overview">
<p>시스템은 4가지 섹션으로 나눠져있다.</p>
<ol>
<li>4개의 카메라로 BEV 이미지를 만든 후 딥러닝 segmentation을 수행한다.</li>
<li>2개의 Wheel encoder + IMU 퓨전을 통해 odometry를 추정한다</li>
<li>Odometry + BEV seg 이미지를 통해 로컬 맵핑 및 글로벌 맵핑을 수행한다.</li>
<li>글로벌 맵 + Odometry + BEV seg 이미지를 EKF로 퓨전해서 visual localization을 수행한다.</li>
</ol>
<p> </p>
<hr>
<h1 id="IPM-이미지-생성"><a href="#IPM-이미지-생성" class="headerlink" title="IPM 이미지 생성"></a>IPM 이미지 생성</h1><img src="/20230218-qin-2020-avpslam/Screenshot%202023-02-28%20at%203.05.05%20PM.png" class="" title="IPM">
<p>전후좌우로 바닥을 바라보는 Fisheye 카메라가 4개가 있다.</p>
<p>Ground plane (i.e. z=0)에 이미지를 projection하는 IPM (Inverse perspective mapping)을 함으로써 Bird’s eye view (BEV) 이미지를 생성한다. IPM 수식은 상당히 스탠다드한 방식을 사용하는 것 처럼 보이는데, 사실 구현에는 굉장히 많은 트릭이 들어갈 것이다.</p>
<p>예를 들어, ground plane을 알아내는것 자체가 쉽지 않다. 자동차가 완벽하게 평평한 면에 있다고 하고 카메라 intrinsic/extrinsic을 정확하게 알고있다면 이론적으로 완벽한 BEV가 나올 것이다. 하지만 여기에는 두가지 문제가 생긴다. </p>
<p>첫번째 문제는, fisheye 카메라간의 overlap 문제이다. 인접한 카메라들끼리는 시점에 대한 오버랩이 분명히 발생하고, 바닥에 projection 했을 때 서로 다른 데이터가 동일한 공간에 projection이 될 것이다. 그러면 어떤 카메라의 데이터를 더 신뢰해야하는가? 왼쪽 카메라의 이미지를 믿어도 되고, 오른쪽 카메라의 이미지를 믿어도 되고, 왼/오 카메라의 이미지를 블렌딩 하는 것도 방법이다. 그런데, 논문에서는 어떤 방법을 사용했는지 말해주지 않는다.</p>
<p>두번째 문제는, 자동차가 운행하면서 extrinsic이 틀어진다는 점이다. 동승자가 자동차에 타면서 무게중심이 바뀌거나 하면 카메라가 고정된 위치를 벗어날 수도 있고,자동차가 가속/감속을 하거나 코너링을 돌면서 무게중심이 바뀌기도 한다. 카메라의 extrinsic이 바뀌면 카메라~바닥면에 대한 기하학적 관계도 바뀐다. 이걸 잡는 방법으로는 뭐 road depth estimation을 한다던지, IMU를 통해 gravity 방향을 받아서 바닥면의 위치를 보정할 수도 있겠다. 하지만 논문에서는 어떤 방법을  사용했는지 말해주지 않는다.</p>
<p> </p>
<hr>
<h1 id="Semantic-feature-detection"><a href="#Semantic-feature-detection" class="headerlink" title="Semantic feature detection"></a>Semantic feature detection</h1><p>Modified U-Net 기반의 CNN을 사용한다고 한다. 사실 BEV 이미지에서 segmentation만 할 수 있다면 어떤 네트워크를 사용하던 상관 없다.</p>
<p>Output class로는 lane, parking lines, guide signs, speed bumps, free space, obstacles, walls 가 있다. 여기서 parking lines, guide signs, speed bumps만 visual localization에 사용한다.</p>
<p>또, parking line을 뽑을 때 parking spot detection task도 함께 수행한다. 보통 parking spot detection 논문들을 보면 parking line을 뽑는 알고리즘도 함께 있다 (i.e. 자주 사용되는 알고리즘이다).</p>
<p> </p>
<hr>
<h1 id="Local-mapping"><a href="#Local-mapping" class="headerlink" title="Local mapping"></a>Local mapping</h1><p>BEV 이미지에서 segmentation이 끝나면, parking lines, guide signs, speed bumps에 대한 정보만 3D space로 lifting 한다. 이는 우리가 생성한 IPM 이미지에 대한 synthesized intrinsic matrix를 inverse 곱 (i.e. unprojection lifting) 하면 된다. </p>
<img src="/20230218-qin-2020-avpslam/Screenshot%202023-02-28%20at%203.18.49%20PM.png" class="" title="eq3">
<p>이 결과, <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex" xmlns="http://www.w3.org/2000/svg" width="6.804ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 3007.3 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path></g><g data-mml-node="mi" transform="translate(278, 0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(850, 0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(1294.7, 0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(1784.7, 0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mn" transform="translate(2229.3, 0)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g><g data-mml-node="mo" transform="translate(2729.3, 0)"><path data-c="5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path></g></g></g></svg></mjx-container>가 나오게 될텐데 (z=0인 이유는 바닥면에 있기 때문에 높이가 0이다), 이를 IMU+Wheel 기반의 odometry로 추정한 6dof 모션에 대해 적용하면 World coordinate 중심에서 3D point를 표현한 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex" xmlns="http://www.w3.org/2000/svg" width="10.5ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 4641.2 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path></g><g data-mml-node="msub" transform="translate(278, 0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mi" transform="translate(572, -150) scale(0.707)"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path></g></g><g data-mml-node="mo" transform="translate(1406.3, 0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(1851, 0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(490, -150) scale(0.707)"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path></g></g><g data-mml-node="mo" transform="translate(2897.2, 0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(3341.9, 0)"><g data-mml-node="mi"><path data-c="1D467" d="M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z"></path></g><g data-mml-node="mi" transform="translate(465, -150) scale(0.707)"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path></g></g><g data-mml-node="mo" transform="translate(4363.2, 0)"><path data-c="5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path></g></g></g></svg></mjx-container> 가 나오게 된다. (IMU+Wheel 기반의 odometry는 추후 섹션에서 추가 설명한다.)</p>
<img src="/20230218-qin-2020-avpslam/Screenshot%202023-02-28%20at%203.18.53%20PM.png" class="" title="eq4">
<p>이 3D point들은 그냥 다 하나의 맵에 때려넣는다.</p>
<p>30m 단위로 local map을 관리한다.</p>
<p> </p>
<hr>
<h1 id="Loop-detection"><a href="#Loop-detection" class="headerlink" title="Loop detection"></a>Loop detection</h1><img src="/20230218-qin-2020-avpslam/Screenshot%202023-02-28%20at%203.46.55%20PM.png" class="" title="loop detection">
<p>아무리 IMU + Odometry를 잘 퓨전해도 drift는 누적된다. 누적되는 drift를 해소하기 위해 loop closure를 해줘야한다.</p>
<p>Loop closure를 하기 위해서는 loop detection 기법이 필요하다. 여기서는 가장 최신의 local map의 위치 주변에 존재하는 과거의 local map들에 대해 ICP (iterative closest point) 기법을 사용해서 relative pose를 구하는 방식을 제안한다.</p>
<p>ICP를 성공했을 경우 relative pose를 구할 수 있고, 이를 loop constraint 삼아서 global pose graph optimzation이 가능해진다. 최적화를 수행하고나면 drift를 해소할 수 있다.</p>
<p> </p>
<hr>
<h1 id="Global-optimization"><a href="#Global-optimization" class="headerlink" title="Global optimization"></a>Global optimization</h1><p>Loop detection이 완료되면 스탠다드한 pose graph optimization을할 수 있다. <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0" xmlns="http://www.w3.org/2000/svg" width="1.826ex" height="1.545ex" role="img" focusable="false" viewBox="0 -683 807 683"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="58" d="M324 614Q291 576 250 573Q231 573 231 584Q231 589 232 592Q235 601 244 614T271 643T324 671T400 683H403Q462 683 481 610Q485 594 490 545T498 454L501 413Q504 413 551 442T648 509T705 561Q707 565 707 578Q707 610 682 614Q667 614 667 626Q667 641 695 662T755 683Q765 683 775 680T796 662T807 623Q807 596 792 572T713 499T530 376L505 361V356Q508 346 511 278T524 148T557 75Q569 69 580 69Q585 69 593 77Q624 108 660 110Q667 110 670 110T676 106T678 94Q668 59 624 30T510 0Q487 0 471 9T445 32T430 71T422 117T417 173Q416 183 416 188Q413 214 411 244T407 286T405 299Q403 299 344 263T223 182T154 122Q152 118 152 105Q152 69 180 69Q183 69 187 66T191 60L192 58V56Q192 41 163 21T105 0Q94 0 84 3T63 21T52 60Q52 77 56 90T85 131T155 191Q197 223 259 263T362 327T402 352L391 489Q391 492 390 505T387 526T384 547T379 568T372 586T361 602T348 611Q346 612 341 613T333 614H324Z"></path></g></g></g></g></svg></mjx-container> 은 과거의 모든 pose를 의미하고, <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.979ex" xmlns="http://www.w3.org/2000/svg" width="4.809ex" height="2.506ex" role="img" focusable="false" viewBox="0 -674.8 2125.8 1107.7"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="msubsup"><g data-mml-node="mi"><path data-c="1D467" d="M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z"></path></g><g data-mml-node="TeXAtom" transform="translate(465, 363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g></g><g data-mml-node="TeXAtom" transform="translate(465, -295.7) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361, 0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(639, 0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(1000, 0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mn" transform="translate(1778, 0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></g></g></svg></mjx-container>는 local map t와 t+1 사이의 상대적인 포즈 변화를 의미한다. 일반적인 Gauss-Newton 최적화로 풀 수 있다.</p>
<img src="/20230218-qin-2020-avpslam/Screenshot%202023-02-28%20at%203.18.11%20PM.png" class="" title="eq5">
<p>Pose graph 최적화가 끝나면, 3D space로 lifting한 semantic landmark들을 최적화된 pose에 맞게 다시 그려넣으면 globally consistent한 semantic map을 만들 수 있다.</p>
<p> </p>
<hr>
<h1 id="Localization"><a href="#Localization" class="headerlink" title="Localization"></a>Localization</h1><img src="/20230218-qin-2020-avpslam/Screenshot%202023-02-28%20at%204.05.37%20PM.png" class="" title="loc">
<p>실시간 visual localization도 가능하다. 이전 과정과 동일하게 4채널 카메라 이미지를 가지고 IPM 이미지를 만든 후 BEV segmentation을 진행한다. BEV seg 이미지를 3D space로 lifting하면 3D landmark가 나올 것이다. 이를 우리가 만들었던 globally consistent한 semantic map에 대해 ICP 알고리즘 (iterative closest point 알고리즘)을 수행함으로써 6dof pose를 구할 수 있다.</p>
<p>논문에서는 ICP를 할 때 initial guess가 중요하다고 한다. 물론 least squares optimization 형태의 ICP 알고리즘은 초기값 설정이 굉장히 중요하지만, 여기서는 아마 그런 의미로 이야기하기보다는, 주차장 특성 상 landmark의 형태가 반복되는 것이 많기 때문에 초기 위치를 정확하게 잡아야 위치 탐색을 잘 할 것이라는 뜻으로 볼 수 있다.</p>
<p>즉, 주차장에서 초기 위치를 잡는 방법이 필요하다는 것이다. 논문에서는 2가지 방법을 제안하는데, 첫번째 방법이 스탠다드한 방법이고 사실 제일 말이 되는 방법이며, 두번째 방법은 feasibility가 거의 없다고 봐야한다.</p>
<p>첫번째 방법은, 주차장의 입구에서 visual localization을 시작한다는 전제를 까는 것이다. 그러면 정해진 local map과 매칭을 하는 것이기 때문에, 정확하게 global pose를 잡고 시작할 수 있을 것이다. 이 방법이 말이 되는 이유는, 주로 Auto valet parking (i.e. AVP… 논문의 이름과 같은)을 만드는 회사들에서 요구하는 시나리오가 ‘고객은 주차장 입구에서 내리고, 자동차는 알아서 빈 곳을 찾아 주차를 하는 시스템’이기 때문이다. 즉, 고객은 무조건 자동차를 주차장 입구에 가져다놔야할 의무가 있다. 이는 기술적 시나리오와 잘 맞기도 한다.</p>
<p>두번째 방법은, 실외에서 차를 끌고 오다가 주차장 입구에서 겨우 닿는 GPS 신호를 통해 초기 위치를 인식하는 방법이다. GPS랑 주차장의 semantic map을 어떻게 연결할지도 얘기가 전혀 없고, 지하주차장으로 들어오면서 날뛰는 GPS 신호를 어떻게 컨트롤 하겠다는 얘기도 없다. 그래서 이 방법은 가볍게 무시해도 될 것같다.</p>
<p>논문에서는 안정적으로 localization을 유지하는 방법도 이야기한다. Semantic feature를 사용하는 localization 방법 특성상, semantic object가 주변에 없을 때 pose tracking이 끊길 가능성이 높다. 실제로 주차장에서 코너를 돌거나 층간 이동을 할 때는 lane이 그려져있지 않거나 parking spot이 주변에 없는 경우들이 있다. 이 경우, 기본적으로 localization 프레임워크가 EKF를 통해 Map + Odometry(IMU+Wheel) 가 연결되어있기 때문에, Map 정보가 없을 경우 (i.e. semantic feature가 안 보일 경우) Odometry를 신뢰하며 이동 값을 추정할 수 있다.</p>
<p> </p>
<hr>
<h1 id="실험-결과"><a href="#실험-결과" class="headerlink" title="실험 결과"></a>실험 결과</h1><p>주로 비교 대상은 Odometry vs ORB-SLAM2 vs AVP-SLAM 이다.</p>
<p>우선 정확도를 보면 ORB-SLAM2와 AVP-SLAM이 가장 우세하다. 근데 여기서 볼 점은, Odometry도 상당히 정확하다는 점이다. AVP-SLAM은 odometry로 motion prior를 갖기 때문에, 기존의 odometry보다는 더 좋은 성능을 보이겠지만 기본적인 odometry가 좋지 않다면 어떤 결과가 나올지 보장할 수 없다.</p>
<img src="/20230218-qin-2020-avpslam/Screenshot%202023-02-28%20at%203.55.05%20PM.png" class="" title="accuracy">
<p>그렇다면 AVP-SLAM을 왜 쓰는가? 사실 Semantic SLAM을 사용하는건 기존의 geometric SLAM 보다 훨씬 더 큰 이점이 있다.</p>
<p>첫번째로는 semantic feature를 검출하는 방법이 data-driven 방식이기 때문에 appearance 변화에 아주 강인하다는 점이다. 그렇기 때문에, ORB-SLAM 같은 경우 조명이 조금만 바뀌어도 정확도가 뚝뚝 떨어지는데에 비해, semantic SLAM의 정확도는 유지될 확률이 높다. 하지만 이건 조명이 바뀌는 경우에 대한 것이고, 지하주차장의 조명이 바뀔 일은 보통 잘 없다.</p>
<p>두번째는 우리가 semantic feature를 선택할 때 domain-specific하게 ‘무조건 static’한 것을 고를 수 있으며, 이는 SLAM기반 reconstruction에 아주 좋은 assumption을 줄 수 있다는 점이다. 주차장은 생각보다 아주 dynamic한 곳이다. 주차되어있는 차는 정적인 것 같지만, 몇시간 후면 주인이 돌아와 차를 뺐을 수도 있다. 비슷하게 생긴 차가 들어와서 repetitive local feature도 생길 수 있다. 그에 비해, parking line이나 guide sign은 절대 변하지 않는다. 이 덕분에 AVP-SLAM은 visual lcoalization을 할 때 아주 높은 Recall-rate를 가질 수 있다.</p>
<img src="/20230218-qin-2020-avpslam/Screenshot%202023-02-28%20at%204.01.14%20PM.png" class="" title="recall rate">
<p>세번째로는 semantic feature를 어떻게 표현하냐에 따라서 최적화가 엄청 쉬워지기도 하고 용량이 줄어들 수도 있다는 점이다. 기존의 VSLAM은 포인트 클라우드 형태의 지도를 가지며, point landmark 하나마다 다수의 descriptor를 담고 있기 때문에 용량을 많이 차지한다. Semantic SLAM은 landmark geometry + class label만 가지는 경우가 많아 굉장히 가볍다. 어떻게 표현하냐에 따라 엄청 가벼워질 수 있다. AVP-SLAM은 사실 지도 용량 최적화는 전혀 하지 않았다 - 오히려 너무 대충한 느낌이다. 그럼에도 불구하고 ORB-SLAM보다 용량이 훨씬 작다.</p>
<img src="/20230218-qin-2020-avpslam/Screenshot%202023-02-28%20at%204.03.39%20PM.png" class="" title="map size">
<p>Parking space detection까지 해서 좋은 geometric map을 가졌다면, 이를 기반으로 path planning + control까지 해서 AVP를 구현할 수 도 있을 것이다.</p>
<img src="/20230218-qin-2020-avpslam/Screenshot%202023-02-28%20at%204.04.46%20PM.png" class="" title="path planning">
<h1 id="Related-works"><a href="#Related-works" class="headerlink" title="Related works"></a>Related works</h1><p>Literature review 섹션에서 Traditional VSLAM과 Road-based localization 기법을 소개한다.</p>
<p>Traditional VSLAM은 다른 VSLAM 논문들에서도 충분히 볼 수 있는 내용이라 이번 리뷰에서는 스킵한다.</p>
<p>Road-based localization에서는 다음과 같은 논문을 추천한다.</p>
<ul>
<li><a href="">Lu 2017 - Monocular localization in urban environments using road marking</a> - Road marker 기준 non-linear optimization 기법 사용</li>
<li><a href="">Regder 2015 - Submap-based slam for road markings</a> - Odometry 기반 포즈 추정 + 이미지 기반 lane 검출 -&gt; Local grid lane map 생성</li>
<li><a href="">Jeong 2017 - Road-slam: Road marking based slam with lane-level accuracy</a> - Road marker classification</li>
</ul>
<p> </p>
<hr>
<h1 id="관련-유투브-영상"><a href="#관련-유투브-영상" class="headerlink" title="관련 유투브 영상"></a>관련 유투브 영상</h1><div class="video-container"><iframe src="https://www.youtube.com/embed/0Ow0U-G7klM" frameborder="0" loading="lazy" allowfullscreen=""></iframe></div>

    </div>

    
    
    
      
  <div class="popular-posts-header">Related Posts</div>
  <ul class="popular-posts">
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="/20230215-rosen-2021/" rel="bookmark">Spatial AI를 만드는 방법 - Rosen 2021 - Advances in Inference and Representation for Simultaneous Localization and Mapping</a></div>
    </li>
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="/20230218-qin-2021-roadmap/" rel="bookmark">Qin 2021 - RoadMap - A Light-Weight Semantic Map for Visual Localization towards Autonomous Driving</a></div>
    </li>
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="/20230329-rosinol-2021-kimera-3d-dgs/" rel="bookmark">Rosinol 2021 - Kimera - from SLAM to Spatial Perception with 3D Dynamic Scene Graphs 논문 리뷰</a></div>
    </li>
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="/20230614-feature-realistic-neural-fusion-for-real-time-open-set-scene-understanding/" rel="bookmark">Mazur 2022 - Feature-Realistic Neural Fusion for Real-Time, Open Set Scene Understanding 논문 리뷰</a></div>
    </li>
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="/20230618-cvpr2023-tutorials-workshops/" rel="bookmark">CVPR 2023 학회에서 눈여겨볼 SLAM 관련 튜토리얼/워크샵</a></div>
    </li>
  </ul>


    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/SLAM/" rel="tag"># SLAM</a>
              <a href="/tags/Visual-SLAM/" rel="tag"># Visual-SLAM</a>
              <a href="/tags/Semantic-SLAM/" rel="tag"># Semantic SLAM</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/20230215-rosen-2021/" rel="prev" title="Spatial AI를 만드는 방법 - Rosen 2021 - Advances in Inference and Representation for Simultaneous Localization and Mapping">
                  <i class="fa fa-chevron-left"></i> Spatial AI를 만드는 방법 - Rosen 2021 - Advances in Inference and Representation for Simultaneous Localization and Mapping
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/20230218-qin-2021-roadmap/" rel="next" title="Qin 2021 - RoadMap - A Light-Weight Semantic Map for Visual Localization towards Autonomous Driving">
                  Qin 2021 - RoadMap - A Light-Weight Semantic Map for Visual Localization towards Autonomous Driving <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    
  
  <div class="comments">
  <script src="https://utteranc.es/client.js" repo="changh95/blog_comments" issue-term="pathname" theme="github-light" crossorigin="anonymous" async></script>
  </div>
  
  

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      const activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      const commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">cv-learn</span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>

    </div>
  </footer>

  
  <script src="//cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/next-boot.js"></script>

  

<script src="/js/local-search.js"></script>



<script>
document.querySelectorAll('.pdfobject-container').forEach(element => {
  const url = element.dataset.target;
  const pdfOpenParams = {
    navpanes : 0,
    toolbar  : 0,
    statusbar: 0,
    pagemode : 'thumbs',
    view     : 'FitH'
  };
  const pdfOpenFragment = '#' + Object.entries(pdfOpenParams).map(([key, value]) => `${key}=${encodeURIComponent(value)}`).join('&');
  const fullURL = `/lib/pdf/web/viewer.html?file=${encodeURIComponent(url)}${pdfOpenFragment}`;

  if (NexT.utils.supportsPDFs()) {
    element.innerHTML = `<embed class="pdfobject" src="${url + pdfOpenFragment}" type="application/pdf" style="height: ${element.dataset.height};">`;
  } else {
    element.innerHTML = `<iframe src="${fullURL}" style="height: ${element.dataset.height};" frameborder="0"></iframe>`;
  }
});
</script>



  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>





  <script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              const target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    const script = document.createElement('script');
    script.src = '//cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js';
    script.defer = true;
    document.head.appendChild(script);
  } else {
    MathJax.startup.document.state(0);
    MathJax.typesetClear();
    MathJax.texReset();
    MathJax.typeset();
  }
</script>



</body>
</html>
